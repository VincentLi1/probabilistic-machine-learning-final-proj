{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassNegativeLogLikelihood,\n",
    "    MulticlassBrierScoreLoss,\n",
    "    MulticlassCalibrationError,\n",
    ")\n",
    "from pathlib import Path\n",
    "from loaders import tiny_imagenet_loader, tiny_imagenet_corrupted_loader  # type: ignore\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Data --------------------------------------------------------------------\n",
    "ROOT = Path(\"data\")          # adjust as needed\n",
    "BATCH_TRAIN = 256\n",
    "BATCH_TEST  = 128\n",
    "\n",
    "train_loader = tiny_imagenet_loader(ROOT, split=\"train\",\n",
    "                                    batch_size=BATCH_TRAIN, shuffle=True,  num_workers=8)\n",
    "val_loader   = tiny_imagenet_loader(ROOT, split=\"val\",\n",
    "                                    batch_size=BATCH_TEST,  shuffle=False, num_workers=8)\n",
    "test_loader  = tiny_imagenet_loader(ROOT, split=\"test\",\n",
    "                                    batch_size=BATCH_TEST,  shuffle=False, num_workers=8)\n",
    "\n",
    "corrupt_loader = tiny_imagenet_corrupted_loader(\n",
    "    ROOT, severity_levels=[1,2,3,4,5],\n",
    "    batch_size=BATCH_TEST, shuffle=False, num_workers=8)\n",
    "NUM_CLASSES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- α‑BatchNorm --------------------------------------------------------------\n",
    "class AlphaBN(nn.BatchNorm2d):\n",
    "    \"\"\"BatchNorm2d that fuses source & target stats at test‑time.\"\"\"\n",
    "    def __init__(self, num_features, alpha=0.9, **kwargs):\n",
    "        super().__init__(num_features, affine=True, track_running_stats=True, **kwargs)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:               # standard BN in training\n",
    "            return super().forward(x)\n",
    "\n",
    "        # Evaluation → blend source stats with batch stats\n",
    "        batch_mean = x.mean([0, 2, 3])\n",
    "        batch_var  = x.var([0, 2, 3], unbiased=False)\n",
    "\n",
    "        # batch_mean is the target mean\n",
    "        # self.running_mean is the source mean\n",
    "        mean = self.alpha * self.running_mean + (1 - self.alpha) * batch_mean\n",
    "        var  = self.alpha * self.running_var  + (1 - self.alpha) * batch_var\n",
    "\n",
    "        return F.batch_norm(x, mean, var, self.weight, self.bias,\n",
    "                            False, 0.0, self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_alpha_bn(module, alpha=0.9):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            setattr(module, name, AlphaBN(child.num_features, alpha=alpha))\n",
    "        else:\n",
    "            convert_to_alpha_bn(child, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Core loss ----------------------------------------------------------------\n",
    "def core_loss(logits):\n",
    "    probs = logits.softmax(dim=1)        # (B, C)\n",
    "    m = probs.mean(dim=0)                # (C,)\n",
    "    outer = torch.outer(m, m)\n",
    "    return outer.sum() - outer.diag().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Train baseline -----------------------------------------------------------\n",
    "def train_baseline(epochs=90, lr=0.1):\n",
    "    model = torchvision.models.resnet50(weights='IMAGENET1K_V2')\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    model = model.to(device)\n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            loss = criterion(model(x), y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        sched.step()\n",
    "        if (epoch+1) % 10 == 0 or epoch==0:\n",
    "            print(f\\\"Epoch {epoch+1}/{epochs} done\\\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Adapt BN affine params on Tiny‑ImageNet‑C --------------------------------\n",
    "def adapt_alpha_bn(model, alpha=0.9, lr=1e-3, epochs=1):\n",
    "    convert_to_alpha_bn(model, alpha)\n",
    "    for p in model.parameters(): p.requires_grad_(False)\n",
    "    bn_params = [m.weight for m in model.modules() if isinstance(m, AlphaBN)] + \\\\\n",
    "                [m.bias   for m in model.modules() if isinstance(m, AlphaBN)]\n",
    "    for p in bn_params: p.requires_grad_(True)\n",
    "    opt = torch.optim.Adam(bn_params, lr=lr)\n",
    "\n",
    "    model.eval()\n",
    "    for _ in range(epochs):\n",
    "        for x, _ in corrupt_loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            loss = core_loss(logits)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Metrics ------------------------------------------------------------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    acc = MulticlassAccuracy(NUM_CLASSES).to(device)\n",
    "    nll = MulticlassNegativeLogLikelihood(NUM_CLASSES).to(device)\n",
    "    brier = MulticlassBrierScoreLoss(NUM_CLASSES).to(device)\n",
    "    ece = MulticlassCalibrationError(NUM_CLASSES, n_bins=15, norm='l1').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs  = logits.softmax(dim=1)\n",
    "\n",
    "            acc.update(probs, y)\n",
    "            nll.update(logits, y)\n",
    "            brier.update(probs, y)\n",
    "            ece.update(probs, y)\n",
    "\n",
    "    print(f\\\"Accuracy                : {acc.compute():.4f}\\\")\n",
    "    print(f\\\"Negative log-likelihood : {nll.compute():.4f}\\\")\n",
    "    print(f\\\"Brier score             : {brier.compute():.4f}\\\")\n",
    "    print(f\\\"Expected calibration err: {ece.compute():.4f}\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Full run -----------------------------------------------------------------\n",
    "# 1. Train or load baseline\n",
    "baseline_ckpt = Path('baseline_resnet50.pth')\n",
    "if baseline_ckpt.exists():\n",
    "    model = torchvision.models.resnet50(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    model.load_state_dict(torch.load(baseline_ckpt, map_location=device))\n",
    "    model = model.to(device)\n",
    "    print('Loaded pretrained baseline.')\n",
    "else:\n",
    "    model = train_baseline()\n",
    "    torch.save(model.state_dict(), baseline_ckpt)\n",
    "\n",
    "print('\\\\nPerformance on clean test set (before adaptation)')\n",
    "evaluate(model, test_loader)\n",
    "\n",
    "# 2. α‑BN + Core adaptation\n",
    "model = adapt_alpha_bn(model, alpha=0.9, lr=1e-3, epochs=1)\n",
    "\n",
    "print('\\\\nPerformance on Tiny‑ImageNet‑C (after adaptation)')\n",
    "evaluate(model, corrupt_loader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
