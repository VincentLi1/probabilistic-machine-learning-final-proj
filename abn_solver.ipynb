{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    # MulticlassNegativeLogLikelihood,\n",
    "    # MulticlassBrierScoreLoss,\n",
    "    MulticlassCalibrationError,\n",
    ")\n",
    "from pathlib import Path\n",
    "from loaders import (\n",
    "    tiny_imagenet_train_loader, \n",
    "    tiny_imagenet_val_loader,\n",
    "    tiny_imagenet_corrupted_loader\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Data --------------------------------------------------------------------\n",
    "BATCH_TRAIN = 128\n",
    "BATCH_VAL  = 128\n",
    "\n",
    "train_loader = tiny_imagenet_train_loader(batch_size=BATCH_TRAIN)\n",
    "val_loader   = tiny_imagenet_val_loader(batch_size=BATCH_VAL)\n",
    "\n",
    "NUM_CLASSES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- α‑BatchNorm --------------------------------------------------------------\n",
    "class AlphaBN(nn.BatchNorm2d):\n",
    "    \"\"\"BatchNorm2d that fuses source & target stats at test‑time.\"\"\"\n",
    "    def __init__(self, num_features, alpha=0.9, **kwargs):\n",
    "        super().__init__(num_features, affine=True, track_running_stats=True, **kwargs)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.to(device)\n",
    "        \n",
    "        if self.training:               # standard BN in training\n",
    "            return super().forward(x)\n",
    "\n",
    "        # Evaluation → blend source stats with batch stats\n",
    "        batch_mean = x.mean([0, 2, 3])\n",
    "        batch_var  = x.var([0, 2, 3], unbiased=False)\n",
    "\n",
    "        # print(self.running_mean.device)\n",
    "        # print(self.running_var.device)\n",
    "        # print(batch_mean.device)\n",
    "        # print(batch_var.device)\n",
    "        # print(self.weight.device)\n",
    "        # print(self.bias.device)\n",
    "\n",
    "        # batch_mean is the target mean\n",
    "        # self.running_mean is the source mean\n",
    "        mean = (self.alpha * self.running_mean + (1 - self.alpha) * batch_mean).detach()\n",
    "        var  = (self.alpha * self.running_var  + (1 - self.alpha) * batch_var).detach()\n",
    "\n",
    "        return F.batch_norm(x, mean, var, self.weight, self.bias,\n",
    "                            False, 0.0, self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_alpha_bn(module, alpha=0.9):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            setattr(module, name, AlphaBN(child.num_features, alpha=alpha))\n",
    "        else:\n",
    "            convert_to_alpha_bn(child, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Core loss ----------------------------------------------------------------\n",
    "def core_loss(logits):\n",
    "    probs = logits.softmax(dim=1)        # (B, C)\n",
    "    m = probs.mean(dim=0)                # (C,)\n",
    "    outer = torch.outer(m, m)\n",
    "    return outer.sum() - outer.diag().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_core_loss(logits):\n",
    "    return torch.sqrt(core_loss(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Train baseline -----------------------------------------------------------\n",
    "def train_baseline(epochs=90, lr=0.1):\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    model.to(device)\n",
    "\n",
    "    best_val_loss = None\n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            loss = loss_fn(model(x), y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        sched.step()\n",
    "\n",
    "        # Periodically validate and save in case of crash\n",
    "        if epoch % 5 == 0:\n",
    "            model.eval()\n",
    "            val_acc, val_loss, val_ece = evaluate(model, val_loader, print_results=False)\n",
    "            model.train()\n",
    "\n",
    "            if not best_val_loss or val_loss < best_val_loss:\n",
    "                torch.save(model.state_dict(), f\"./models/bn_train3.pt\")\n",
    "                best_val = val_acc\n",
    "            elif val_loss > best_val_loss + 1:\n",
    "                print(\"Early stop because of degredation in validation loss\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Training loss: {loss.item()}\")\n",
    "            print(f\"Validation loss: {val_loss}\")\n",
    "            print(f\"Validation accuracy: {val_acc}\")\n",
    "            \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Adapt BN affine params on Tiny‑ImageNet‑C --------------------------------\n",
    "def adapt_alpha_bn(model, test_loader, device, loss=\"core\", alpha=0.9, lr=1e-3, epochs=1):\n",
    "    \"\"\" Loss is core or sqrt core \"\"\"\n",
    "\n",
    "    assert loss in [\"core\", \"root_core\"]\n",
    "\n",
    "    if loss == \"core\":\n",
    "        loss_fn = core_loss\n",
    "    elif loss == \"root_core\":\n",
    "        loss_fn = root_core_loss\n",
    "    \n",
    "    convert_to_alpha_bn(model, alpha)\n",
    "    model.to(device)\n",
    "    for p in model.parameters(): p.requires_grad_(False)\n",
    "    bn_params = [m.weight for m in model.modules() if isinstance(m, AlphaBN)] + \\\n",
    "                [m.bias   for m in model.modules() if isinstance(m, AlphaBN)]\n",
    "    for p in bn_params: p.requires_grad_(True)\n",
    "    opt = torch.optim.Adam(bn_params, lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for _ in tqdm(range(epochs), desc=\"Adapting\", leave=False):\n",
    "        for x, _ in test_loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            loss = core_loss(logits)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Metrics ------------------------------------------------------------------\n",
    "def evaluate(model, loader, print_results=True):\n",
    "    model.eval()\n",
    "    ece = MulticlassCalibrationError(NUM_CLASSES, n_bins=15, norm='l1').to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs  = logits.softmax(dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            total_correct += (preds==y).sum()\n",
    "            total_loss += loss_fn(probs, y).item()\n",
    "            total_samples += y.size(0)\n",
    "            ece.update(probs, y)\n",
    "\n",
    "    loss = total_loss / total_samples\n",
    "    accuracy = total_correct/total_samples\n",
    "\n",
    "    if print_results:\n",
    "        print(f\"Accuracy                : {accuracy:.4f}\")\n",
    "        print(f\"Cross-Entropy Loss      : {loss:.4f}\")\n",
    "        print(f\"Expected calibration err: {ece.compute():.4f}\")\n",
    "\n",
    "    print(f\"{total_correct} / {total_samples}\")\n",
    "\n",
    "    return accuracy, loss, ece.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\n",
      "\n",
      "Training Results\n",
      "\n",
      "Test Results\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f2b344de9949ba86082ee54feb4387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                : 0.2013\n",
      "Cross-Entropy Loss      : 0.0405\n",
      "Expected calibration err: 0.3850\n",
      "2013 / 10000\n"
     ]
    }
   ],
   "source": [
    "# ---- Full run -----------------------------------------------------------------\n",
    "# 1. Train or load baseline\n",
    "baseline_ckpt = Path('models/sgd_model.pt')\n",
    "if baseline_ckpt.exists():\n",
    "    print('Loading pretrained model')\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    model.load_state_dict(torch.load(baseline_ckpt, map_location=device))\n",
    "    model.to(device)\n",
    "else:\n",
    "    print('Training model froms scratch')\n",
    "    model = train_baseline(epochs=100)\n",
    "    torch.save(model.state_dict(), baseline_ckpt)\n",
    "\n",
    "print('\\nTraining Results')\n",
    "# accl, loss, ece = evaluate(model, train_loader)\n",
    "\n",
    "print('\\nTest Results')\n",
    "acc, loss, ece = evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6757286c9274fe298fa8ae3c7fb8df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                : 0.1058\n",
      "Cross-Entropy Loss      : 0.0412\n",
      "Expected calibration err: 0.4541\n",
      "1058 / 10000\n"
     ]
    }
   ],
   "source": [
    "# 1.5 Test model without adaptation\n",
    "\n",
    "corrupt_loader = tiny_imagenet_corrupted_loader(\n",
    "    corruption='brightness', \n",
    "    severity=1, \n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "acc, loss, ece = evaluate(model, corrupt_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4d106cea5f4096af4156ed511c0534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adapting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on Tiny‑ImageNet‑C (after adaptation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0cb6539b584c52ab0d580f93a9fbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                : 0.1715\n",
      "Cross-Entropy Loss      : 0.0408\n",
      "Expected calibration err: 0.3567\n",
      "1715 / 10000\n"
     ]
    }
   ],
   "source": [
    "# 2. α‑BN + Core adaptation (look at brightness-1 for example)\n",
    "adapted_model_core = adapt_alpha_bn(\n",
    "    model, \n",
    "    test_loader=corrupt_loader, \n",
    "    loss=\"core\", \n",
    "    device=device, \n",
    "    alpha=0.7, \n",
    "    lr=1e-4, \n",
    "    epochs=1\n",
    ")\n",
    "\n",
    "print('\\nPerformance on Tiny‑ImageNet‑C (after adaptation)')\n",
    "acc, loss, ece = evaluate(adapted_model_core, corrupt_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce2f16cf89e494dbf23aa9b342da882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adapting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on Tiny‑ImageNet‑C (after adaptation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c5553c32b848729003ef85f9ad29f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                : 0.1687\n",
      "Cross-Entropy Loss      : 0.0408\n",
      "Expected calibration err: 0.3587\n",
      "1687 / 10000\n"
     ]
    }
   ],
   "source": [
    "adapted_model_root_core = adapt_alpha_bn(\n",
    "    model, \n",
    "    test_loader=corrupt_loader, \n",
    "    loss=\"root_core\", \n",
    "    device=device, \n",
    "    alpha=0.7, \n",
    "    lr=1e-4, \n",
    "    epochs=1\n",
    ")\n",
    "\n",
    "print('\\nPerformance on Tiny‑ImageNet‑C (after adaptation)')\n",
    "acc, loss, ece = evaluate(adapted_model_root_core, corrupt_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7feeb9f4757a4bcf8689c6c89cf4d341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adapting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce667069ed4e7db07a6bd17dfda78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718 / 10000\n",
      "brightness L1: 0.17180000245571136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2f7a6dc9af4f4b838264bbed1e274a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adapting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7380143a0c9432b8e34cf8df629122a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973 / 10000\n",
      "contrast L1: 0.09730000048875809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8417b056bb8453594224199768bc668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adapting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ba56ecb1304961b62ba22308ed1e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479 / 10000\n",
      "defocus_blur L1: 0.14790000021457672\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\")\n",
    "\n",
    "corruptions = [\"brightness\", \"contrast\", \"defocus_blur\"]\n",
    "\n",
    "loss_type=\"root_core\"\n",
    "\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "for corruption in corruptions:\n",
    "    for level in range(1, 2):\n",
    "\n",
    "        # Get the loader\n",
    "        test_loader = tiny_imagenet_corrupted_loader(\n",
    "            corruption,\n",
    "            severity=level,\n",
    "            batch_size=128,\n",
    "            root='./data/Tiny-ImageNet-C',\n",
    "            num_workers=1\n",
    "        )\n",
    "\n",
    "        # Tune the model\n",
    "        adapted_model = adapt_alpha_bn(\n",
    "            model, \n",
    "            test_loader=corrupt_loader, \n",
    "            loss=loss_type, \n",
    "            device=device, \n",
    "            alpha=0.7, \n",
    "            lr=1e-4, \n",
    "            epochs=1\n",
    "        )\n",
    "        \n",
    "        test_accuracy, _, _ = evaluate(adapted_model, test_loader, print_results=False)\n",
    "\n",
    "        keys.append(corruption + \"-\" + str(level))\n",
    "        values.append(test_accuracy.item())\n",
    "    \n",
    "        print(f\"{corruption} L{level}: {test_accuracy}\")\n",
    "\n",
    "# Save all values\n",
    "with open(f\"results/abn_{loss_type}_results.json\", \"w\") as file:\n",
    "    json.dump(dict(zip(keys, values)), file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pml_env_dist] *",
   "language": "python",
   "name": "conda-env-.conda-pml_env_dist-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
