{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    # MulticlassNegativeLogLikelihood,\n",
    "    # MulticlassBrierScoreLoss,\n",
    "    MulticlassCalibrationError,\n",
    ")\n",
    "from pathlib import Path\n",
    "from loaders import (\n",
    "    tiny_imagenet_train_loader, \n",
    "    tiny_imagenet_val_loader,\n",
    "    tiny_imagenet_corrupted_loader\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Data --------------------------------------------------------------------\n",
    "BATCH_TRAIN = 128\n",
    "BATCH_VAL  = 128\n",
    "\n",
    "train_loader = tiny_imagenet_train_loader(batch_size=BATCH_TRAIN)\n",
    "val_loader   = tiny_imagenet_val_loader(batch_size=BATCH_VAL)\n",
    "\n",
    "NUM_CLASSES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- α‑BatchNorm --------------------------------------------------------------\n",
    "class AlphaBN(nn.BatchNorm2d):\n",
    "    \"\"\"BatchNorm2d that fuses source & target stats at test‑time.\"\"\"\n",
    "    def __init__(self, num_features, alpha=0.9, **kwargs):\n",
    "        super().__init__(num_features, affine=True, track_running_stats=True, **kwargs)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.to(device)\n",
    "        \n",
    "        if self.training:               # standard BN in training\n",
    "            return super().forward(x)\n",
    "\n",
    "        # Evaluation → blend source stats with batch stats\n",
    "        batch_mean = x.mean([0, 2, 3])\n",
    "        batch_var  = x.var([0, 2, 3], unbiased=False)\n",
    "\n",
    "        # print(self.running_mean.device)\n",
    "        # print(self.running_var.device)\n",
    "        # print(batch_mean.device)\n",
    "        # print(batch_var.device)\n",
    "        # print(self.weight.device)\n",
    "        # print(self.bias.device)\n",
    "\n",
    "        # batch_mean is the target mean\n",
    "        # self.running_mean is the source mean\n",
    "        mean = (self.alpha * self.running_mean + (1 - self.alpha) * batch_mean).detach()\n",
    "        var  = (self.alpha * self.running_var  + (1 - self.alpha) * batch_var).detach()\n",
    "\n",
    "        return F.batch_norm(x, mean, var, self.weight, self.bias,\n",
    "                            False, 0.0, self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_alpha_bn(module, alpha=0.9):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            setattr(module, name, AlphaBN(child.num_features, alpha=alpha))\n",
    "        else:\n",
    "            convert_to_alpha_bn(child, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Core loss ----------------------------------------------------------------\n",
    "def core_loss(logits):\n",
    "    probs = logits.softmax(dim=1)        # (B, C)\n",
    "    m = probs.mean(dim=0)                # (C,)\n",
    "    outer = torch.outer(m, m)\n",
    "    return outer.sum() - outer.diag().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Train baseline -----------------------------------------------------------\n",
    "def train_baseline(epochs=90, lr=0.1):\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    model.to(device)\n",
    "\n",
    "    best_val_loss = None\n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            loss = loss_fn(model(x), y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        sched.step()\n",
    "\n",
    "        # Periodically validate and save in case of crash\n",
    "        if epoch % 5 == 0:\n",
    "            model.eval()\n",
    "            val_acc, val_loss, val_ece = evaluate(model, val_loader, print_results=False)\n",
    "            model.train()\n",
    "\n",
    "            if not best_val_loss or val_loss < best_val_loss:\n",
    "                torch.save(model.state_dict(), f\"./models/bn_train3.pt\")\n",
    "                best_val = val_acc\n",
    "            elif val_loss > best_val_loss + 1:\n",
    "                print(\"Early stop because of degredation in validation loss\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Training loss: {loss.item()}\")\n",
    "            print(f\"Validation loss: {val_loss}\")\n",
    "            print(f\"Validation accuracy: {val_acc}\")\n",
    "            \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Adapt BN affine params on Tiny‑ImageNet‑C --------------------------------\n",
    "def adapt_alpha_bn(model, test_loader, device, alpha=0.9, lr=1e-3, epochs=1):\n",
    "    convert_to_alpha_bn(model, alpha)\n",
    "    model.to(device)\n",
    "    for p in model.parameters(): p.requires_grad_(False)\n",
    "    bn_params = [m.weight for m in model.modules() if isinstance(m, AlphaBN)] + \\\n",
    "                [m.bias   for m in model.modules() if isinstance(m, AlphaBN)]\n",
    "    for p in bn_params: p.requires_grad_(True)\n",
    "    opt = torch.optim.Adam(bn_params, lr=lr)\n",
    "\n",
    "    model.eval()\n",
    "    for _ in range(epochs):\n",
    "        for x, _ in test_loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            loss = core_loss(logits)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Metrics ------------------------------------------------------------------\n",
    "def evaluate(model, loader, print_results=True):\n",
    "    model.eval()\n",
    "    ece = MulticlassCalibrationError(NUM_CLASSES, n_bins=15, norm='l1').to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs  = logits.softmax(dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            total_correct += (preds==y).sum()\n",
    "            total_loss += loss_fn(probs, y).item()\n",
    "            total_samples += y.size(0)\n",
    "            ece.update(probs, y)\n",
    "\n",
    "    loss = total_loss / total_samples\n",
    "    accuracy = total_correct/total_samples\n",
    "\n",
    "    if print_results:\n",
    "        print(f\"Accuracy                : {accuracy:.4f}\")\n",
    "        print(f\"Cross-Entropy Loss      : {loss:.4f}\")\n",
    "        print(f\"Expected calibration err: {ece.compute():.4f}\")\n",
    "\n",
    "    print(f\"{total_correct} / {total_samples}\")\n",
    "\n",
    "    return accuracy, loss, ece.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model froms scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be457959ed7346be9ea378b5f74879d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c383bdc435a44b26bcc44cac855bb14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 / 10000\n",
      "Training loss: 3.572425603866577\n",
      "Validation loss: 0.04186589994430542\n",
      "Validation accuracy: 0.0032999999821186066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e362332832384928a06eac1099ad5e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 / 10000\n",
      "Training loss: 2.0659303665161133\n",
      "Validation loss: 0.04187268214225769\n",
      "Validation accuracy: 0.0032999999821186066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b2890fe93d4f17a4a1189120751da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 / 10000\n",
      "Training loss: 1.18183434009552\n",
      "Validation loss: 0.0418758994102478\n",
      "Validation accuracy: 0.004399999976158142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecefeb8f507443082f31731df532321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 / 10000\n",
      "Training loss: 1.0925800800323486\n",
      "Validation loss: 0.04186864032745361\n",
      "Validation accuracy: 0.0050999997183680534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc823fe3e8147a6a5318e1a58748c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 / 10000\n",
      "Training loss: 0.2996460199356079\n",
      "Validation loss: 0.04187883596420288\n",
      "Validation accuracy: 0.0037999998312443495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b766ca4d3fc142ba85af120594d2a7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 / 10000\n",
      "Training loss: 0.5105670094490051\n",
      "Validation loss: 0.04187023587226868\n",
      "Validation accuracy: 0.005499999970197678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecf444a91a14b7fb3706cbc42809948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 / 10000\n",
      "Training loss: 0.48891907930374146\n",
      "Validation loss: 0.04187819495201111\n",
      "Validation accuracy: 0.004100000020116568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026c055e32264b739392047910992d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 / 10000\n",
      "Training loss: 0.5407708287239075\n",
      "Validation loss: 0.04186956348419189\n",
      "Validation accuracy: 0.005399999674409628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8674a1e6159d44b3b070740069ddfbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 / 10000\n",
      "Training loss: 0.42343729734420776\n",
      "Validation loss: 0.0418816900730133\n",
      "Validation accuracy: 0.003399999812245369\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c571d0e1704131bb92b717f8c06f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 / 10000\n",
      "Training loss: 0.035032011568546295\n",
      "Validation loss: 0.041879119968414306\n",
      "Validation accuracy: 0.004399999976158142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5735f5fca46d4176830df16ff651f807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 / 10000\n",
      "Training loss: 0.01116199605166912\n",
      "Validation loss: 0.0418783745765686\n",
      "Validation accuracy: 0.0038999998942017555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37e7bfecfa84e8f96d24aa585be2c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 / 10000\n",
      "Training loss: 0.006530293263494968\n",
      "Validation loss: 0.04187610306739807\n",
      "Validation accuracy: 0.00419999985024333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add89f5cc5234c239d535668eab0f3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 / 10000\n",
      "Training loss: 0.007940402254462242\n",
      "Validation loss: 0.04187455854415893\n",
      "Validation accuracy: 0.0044999998062849045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2189ce926e994becb790d5a9ac8f2b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 / 10000\n",
      "Training loss: 0.02485503815114498\n",
      "Validation loss: 0.041874964570999144\n",
      "Validation accuracy: 0.004399999976158142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6648a91465b4512878638e5bf7ff015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 / 10000\n",
      "Training loss: 0.02109863981604576\n",
      "Validation loss: 0.04186923699378967\n",
      "Validation accuracy: 0.004100000020116568\n"
     ]
    }
   ],
   "source": [
    "# ---- Full run -----------------------------------------------------------------\n",
    "# 1. Train or load baseline\n",
    "baseline_ckpt = Path('models/bn_baseline_model3.pt')\n",
    "if baseline_ckpt.exists():\n",
    "    print('Loading pretrained model')\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    model.load_state_dict(torch.load(baseline_ckpt, map_location=device))\n",
    "    model.to(device)\n",
    "else:\n",
    "    print('Training model froms scratch')\n",
    "    model = train_baseline(epochs=100)\n",
    "    torch.save(model.state_dict(), baseline_ckpt)\n",
    "\n",
    "print('\\nTraining Results')\n",
    "# accl, loss, ece = evaluate(model, train_loader)\n",
    "\n",
    "print('\\nTest Results')\n",
    "acc, loss, ece = evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Test model without adaptation\n",
    "\n",
    "corrupt_loader = tiny_imagenet_corrupted_loader(\n",
    "    corruption='brightness', \n",
    "    severity=1, \n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "acc, loss, ece = evaluate(model, corrupt_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. α‑BN + Core adaptation (look at brightness-1 for example)\n",
    "adapted_model = adapt_alpha_bn(model, test_loader=corrupt_loader, device=device, alpha=0.9, lr=1e-3, epochs=1)\n",
    "\n",
    "print('\\nPerformance on Tiny‑ImageNet‑C (after adaptation)')\n",
    "acc, loss, ece = evaluate(adapted_model, corrupt_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pml_env_dist] *",
   "language": "python",
   "name": "conda-env-.conda-pml_env_dist-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
